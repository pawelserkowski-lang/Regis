import os
import sys

def write_file(filename, content):
    """Pomocnicza funkcja do zapisu plikÃ³w z informacjÄ… zwrotnÄ…."""
    try:
        # Zapewniamy, Å¼e katalogi istniejÄ…
        os.makedirs(os.path.dirname(filename) or ".", exist_ok=True)
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content.strip())
        print(f"âœ… Naprawiono/Utworzono: {filename}")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d zapisu {filename}: {e}")

# ==========================================
# 1. gemini-extension.json (UzupeÅ‚niony o konfiguracjÄ™)
# ==========================================
gemini_extension_content = """
{
  "name": "Jules-Regis-Interface",
  "version": "1.3.0",
  "description": "Lokalny orkiestrator i Cyberdeck dla agenta Jules. Zoptymalizowany pod kÄ…tem kosztÃ³w i bezpieczeÅ„stwa.",
  "publisher": "PawelSerkowski",
  "specVersion": "1.0",
  "extension": {
    "type": "panel",
    "entryPoint": "dist-electron/main.js",
    "capabilities": ["file-system", "network-access"]
  },
  "configuration": {
    "properties": {
      "GEMINI_API_KEY": {
        "type": "string",
        "description": "Klucz API Google Gemini wymagany do dziaÅ‚ania mÃ³zgu Julesa.",
        "required": true
      }
    }
  },
  "permissions": [
    "run-shell-command",
    "read-file",
    "write-file"
  ]
}
"""

# ==========================================
# 2. gemini_client.py (Dodano klasÄ™ GeminiGuard)
# ==========================================
# UÅ¼ywamy eskejpowania \"\"\" dla docstringÃ³w wewnÄ…trz zmiennej
gemini_client_content = """
import os
import logging
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted, ServiceUnavailable, InternalServerError
from tenacity import (
    retry,
    wait_random_exponential,
    stop_after_attempt,
    retry_if_exception_type,
    before_sleep_log
)

logger = logging.getLogger(__name__)

class GeminiGuard:
    \"\"\"
    Wrapper na klienta Gemini zapewniajÄ…cy obsÅ‚ugÄ™ bÅ‚Ä™dÃ³w, retry policy
    oraz (w przyszÅ‚oÅ›ci) zliczanie tokenÃ³w.
    \"\"\"
    def __init__(self, api_key=None, model_name="gemini-2.0-flash-exp"):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            # Fallback dla testÃ³w lokalnych - OSTRZEÅ»ENIE
            logger.warning("Brak GEMINI_API_KEY. PrÃ³ba uruchomienia w trybie mock (jeÅ›li brak klucza).")
            # W produkcji tutaj powinien byÄ‡ raise ValueError
        
        if self.api_key:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel(model_name)
        else:
            self.model = None

    @retry(
        wait=wait_random_exponential(multiplier=1, max=60),
        stop=stop_after_attempt(5),
        retry=retry_if_exception_type((ResourceExhausted, ServiceUnavailable, InternalServerError)),
        before_sleep=before_sleep_log(logger, logging.WARNING)
    )
    def generate_content(self, prompt, temperature=0.7):
        if not self.model:
             return "[[MOCK RESPONSE: Brak klucza API. Ustaw GEMINI_API_KEY.]]"
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature
                )
            )
            return response.text
        except Exception as e:
            logger.error(f"BÅ‚Ä…d generowania treÅ›ci: {e}")
            raise

    async def generate_content_async(self, prompt, temperature=0.7):
        \"\"\"Wersja asynchroniczna dla moduÅ‚u debaty.\"\"\"
        import asyncio
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self.generate_content, prompt, temperature)

# Funkcja dla wstecznej kompatybilnoÅ›ci z regis.py
def generate_content_safe(prompt, model_name="gemini-2.0-flash-exp"):
    guard = GeminiGuard(model_name=model_name)
    return guard.generate_content(prompt)
"""

# ==========================================
# 3. memory_manager.py (NOWY PLIK - Optymalizacja TokenÃ³w)
# ==========================================
memory_manager_content = """
import logging

logger = logging.getLogger(__name__)

class MemoryManager:
    \"\"\"ZarzÄ…dza pamiÄ™ciÄ… podrÄ™cznÄ… agenta.\"\"\"
    def __init__(self):
        self.history = []

    def add_message(self, role, content):
        self.history.append({"role": role, "content": content})
        # Prosta polityka retencji - trzymamy ostatnie 50 wiadomoÅ›ci
        if len(self.history) > 50:
            self.history.pop(0)

    def get_context_string(self):
        return "\\n".join([f"{msg['role'].upper()}: {msg['content']}" for msg in self.history])

async def optimize_context(history, max_tokens=4000, model_client=None):
    \"\"\"
    Inteligentnie skracanie historii.
    JeÅ›li historia jest dÅ‚uga, podsumowuje starsze wpisy.
    \"\"\"
    # Symulacja liczenia tokenÃ³w (1 sÅ‚owo ~= 1.3 tokena)
    estimated_tokens = sum(len(str(m.get('content', ''))) for m in history) // 3
    
    if estimated_tokens < max_tokens:
        return history

    logger.info("ğŸ”ª Wykryto przekroczenie limitu tokenÃ³w. Optymalizacja kontekstu...")
    
    # Zachowaj ostatnie 3 wiadomoÅ›ci bez zmian
    recent_history = history[-3:]
    old_history = history[:-3]

    if not old_history:
        return recent_history

    summary_text = f"[System: Poprzednie {len(old_history)} rund debaty zostaÅ‚o zarchiwizowane ze wzglÄ™du na limit pamiÄ™ci.]"
    
    optimized_history = [{"role": "system", "content": summary_text}] + recent_history
    return optimized_history
"""

# ==========================================
# 4. io_guard.py (Dodano klasÄ™ IOGuard i Atomic Write)
# ==========================================
io_guard_content = """
import json
import os
import aiofiles
import argparse
import asyncio
# Importujemy SimpleDebate wewnÄ…trz funkcji main, aby uniknÄ…Ä‡ problemÃ³w przy imporcie cyklicznym,
# lub jeÅ›li plik debaty jeszcze nie istnieje w momencie startu interpretera (rzadkie, ale moÅ¼liwe w fix script).

STATUS_FILE = "status_report.json"

class IOGuard:
    \"\"\"
    ZarzÄ…dza bezpiecznym zapisem i odczytem stanu (Atomic Write).
    Chroni przed uszkodzeniem pliku JSON przy przerwaniu zasilania lub race condition.
    \"\"\"
    
    @staticmethod
    async def read_json(filepath=STATUS_FILE):
        if not os.path.exists(filepath):
            return {}
        try:
            async with aiofiles.open(filepath, 'r', encoding='utf-8') as f:
                content = await f.read()
                return json.loads(content)
        except Exception:
            return {}

    @staticmethod
    async def write_json(data, filepath=STATUS_FILE):
        # Atomic write: zapisz do .tmp, potem zmieÅ„ nazwÄ™
        temp_file = f"{filepath}.tmp"
        try:
            async with aiofiles.open(temp_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(data, indent=2, ensure_ascii=False))
            
            # Atomowa operacja zmiany nazwy (wymaga os.remove na Windows jeÅ›li plik istnieje)
            if os.path.exists(filepath):
                try:
                    os.replace(temp_file, filepath)
                except OSError:
                    os.remove(filepath)
                    os.rename(temp_file, filepath)
            else:
                os.rename(temp_file, filepath)
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d zapisu IOGuard: {e}")
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass

def main():
    parser = argparse.ArgumentParser(description="Regis CLI - System ZarzÄ…dzania i Debaty AI")
    subparsers = parser.add_subparsers(dest="command", help="DostÄ™pne komendy")

    # Komenda: debate
    debate_parser = subparsers.add_parser("debate", help="Uruchom debatÄ™ miÄ™dzy agentami")
    debate_parser.add_argument("topic", nargs="+", help="Temat debaty")

    # Komenda: status
    status_parser = subparsers.add_parser("status", help="SprawdÅº status systemu")

    args = parser.parse_args()

    if args.command == "debate":
        # Import tutaj (lazy import)
        try:
            from debate import SimpleDebate
            topic = " ".join(args.topic)
            print(f"ğŸ™ï¸ Rozpoczynam debatÄ™ na temat: {topic}")
            engine = SimpleDebate()
            asyncio.run(engine.run(topic))
        except ImportError:
            print("âŒ BÅ‚Ä…d: Nie znaleziono moduÅ‚u 'debate'. Uruchom fix_jules.py ponownie.")
        except Exception as e:
            print(f"âŒ WystÄ…piÅ‚ bÅ‚Ä…d krytyczny: {e}")

    elif args.command == "status":
        print("âœ… System Regis: ONLINE")
        if os.path.exists(STATUS_FILE):
            with open(STATUS_FILE, 'r', encoding='utf-8') as f:
                print(f"ğŸ“„ Ostatni status: {f.read()}")
        else:
            print("   Brak pliku statusu.")

    else:
        parser.print_help()

if __name__ == "__main__":
    main()
"""

# ==========================================
# 5. debate.py (Dodano klasÄ™ SimpleDebate i naprawiono importy)
# ==========================================
debate_content = """
import asyncio
import logging
import os
from gemini_client import GeminiGuard
from memory_manager import optimize_context

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleDebate:
    \"\"\"
    Klasa orkiestratora debaty.
    \"\"\"
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        # JeÅ›li brak klucza, GeminiGuard obsÅ‚uÅ¼y to ostrzeÅ¼eniem, ale debata moÅ¼e nie mieÄ‡ sensu.
        self.client = GeminiGuard(self.api_key)

    async def debate_round(self, topic, stance_a, stance_b, round_num, history):
        # Import wewnÄ…trz metody, aby uniknÄ…Ä‡ cyklicznego importu z io_guard
        from io_guard import IOGuard
        
        logger.info(f"--- Runda {round_num}: {topic} ---")

        # 1. Optymalizacja pamiÄ™ci
        history = await optimize_context(history, max_tokens=2000, model_client=self.client)

        # 2. Agent A (Pro)
        # UÅ¼ywamy f-stringa z potrÃ³jnym cudzysÅ‚owem (escaped)
        prompt_a = f\"\"\"
        JesteÅ› Agentem A. Bronisz tezy: {stance_a}.
        Temat: {topic}.
        Historia dyskusji: {history}
        
        Twoja odpowiedÅº musi byÄ‡ zwiÄ™zÅ‚a (max 3 zdania). UÅ¼yj mocnych argumentÃ³w.
        \"\"\"
        response_a = await self.client.generate_content_async(prompt_a)
        history.append({"role": "Agent A", "content": response_a})
        print(f"ğŸ”µ Agent A: {response_a}")

        # Zapis statusu
        status_data = await IOGuard.read_json()
        status_data.update({
            'last_message': response_a,
            'current_round': round_num,
            'speaker': 'Agent A'
        })
        await IOGuard.write_json(status_data)

        # 3. Agent B (Contra)
        prompt_b = f\"\"\"
        JesteÅ› Agentem B. Bronisz tezy: {stance_b}.
        OdnieÅ› siÄ™ krytycznie do argumentu Agenta A: "{response_a}"
        
        BÄ…dÅº cyniczny i zabawny. Max 3 zdania.
        \"\"\"
        response_b = await self.client.generate_content_async(prompt_b)
        history.append({"role": "Agent B", "content": response_b})
        print(f"ğŸ”´ Agent B: {response_b}")

        # Zapis statusu
        status_data['last_message'] = response_b
        status_data['speaker'] = 'Agent B'
        await IOGuard.write_json(status_data)

        return history

    async def run(self, topic, rounds=3):
        from io_guard import IOGuard
        
        history = []
        await IOGuard.write_json({"status": "active", "topic": topic, "rounds": rounds})
        
        for i in range(rounds):
            history = await self.debate_round(topic, "Jestem ZA", "Jestem PRZECIW", i+1, history)
            await asyncio.sleep(1) # Oddech dla API
            
        await IOGuard.write_json({"status": "finished", "final_history": history})
        logger.info("Debata zakoÅ„czona sukcesem.")
        return history
"""

# ==========================================
# 6. regis.py (Aktualizacja importÃ³w i obsÅ‚ugi bÅ‚Ä™dÃ³w)
# ==========================================
regis_content = """
import threading
import logging
from typing import Dict, Any
from memory_manager import MemoryManager
from gemini_client import generate_content_safe

# Definicje bÅ‚Ä™dÃ³w (Hierarchia)
class RegisError(Exception): pass
class BrainConnectionError(RegisError): pass
class ContextError(RegisError): pass

logger = logging.getLogger(__name__)
processing_lock = threading.Lock()
memory = MemoryManager()

def process_request(payload: Dict[str, Any]) -> str:
    if processing_lock.locked():
        logger.warning("System zajÄ™ty. Oczekiwanie na zwolnienie zasobÃ³w...")
    
    with processing_lock:
        return _safe_execute(payload)

def _safe_execute(payload: Dict[str, Any]) -> str:
    mode = payload.get("mode")
    target_file = payload.get("target_file")
    user_context = payload.get("user_context")

    logger.info(f"Processing mode: {mode}")

    # Budowanie promptu z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w plikowych
    prompt_parts = [f"Mode: {mode}."]
    
    if target_file:
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                content = f.read()
            # UÅ¼ywamy eskejpowania backslashy dla newlines w f-stringu zapisanym do pliku
            prompt_parts.append(f"Input file ({target_file}):\\n```\\n{content}\\n```")
        except FileNotFoundError:
            return f"âŒ BÅ‚Ä…d: Nie znaleziono pliku {target_file}"
        except Exception as e:
            return f"âŒ BÅ‚Ä…d odczytu pliku: {str(e)}"

    if user_context:
        prompt_parts.append(f"Context: {user_context}")

    final_prompt = "\\n".join(prompt_parts)
    memory.add_message("user", final_prompt)

    try:
        response_text = generate_content_safe(final_prompt)
        memory.add_message("model", response_text)
        return response_text

    except Exception as e:
        logger.error(f"Critical Brain Failure: {e}")
        raise BrainConnectionError(f"Nie udaÅ‚o siÄ™ poÅ‚Ä…czyÄ‡ z API Gemini: {e}")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    print("Regis Core System Loaded.")
"""

# Wykonanie nadpisywania plikÃ³w
print("ğŸš€ Rozpoczynam (ponownie) procedurÄ™ naprawczÄ… projektu Jules-Regis...")
write_file("gemini-extension.json", gemini_extension_content)
write_file("gemini_client.py", gemini_client_content)
write_file("memory_manager.py", memory_manager_content)
write_file("io_guard.py", io_guard_content)
write_file("debate.py", debate_content)
write_file("regis.py", regis_content)

print("\\nâœ… PROCES ZAKOÅƒCZONY.")
print("ğŸ‘‰ Uruchom 'python regis_cli.py chat' aby przetestowaÄ‡ podstawy.")
print("ğŸ‘‰ Uruchom 'python io_guard.py debate \"Czy programiÅ›ci AI Å›niÄ… o elektrycznych owcach?\"'")